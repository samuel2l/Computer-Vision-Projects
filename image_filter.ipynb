{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGE FILTERING AND EDGE DETECTION\n",
    "import numpy as np\n",
    "import cv2\n",
    "# Filter Modes\n",
    "PREVIEW = 0    # No filter, just preview\n",
    "BLUR = 1       # Blur filter\n",
    "FEATURES = 2   # Corner feature detection\n",
    "CANNY = 3      # Canny Edge Detector\n",
    "# PREVIEW: This mode is used to display the video feed without applying any filters.\n",
    "# BLUR: In this mode, a blur filter will be applied to the video feed.\n",
    "# FEATURES: This mode applies corner feature detection, which identifies key points (corners) in the image.\n",
    "# CANNY: This is the mode for Canny Edge Detection, which highlights edges in the image.\n",
    "\n",
    "# Parameters for corner feature detection\n",
    "feature_params = dict(maxCorners=500,\n",
    "                      qualityLevel=0.2,\n",
    "                      minDistance=15,\n",
    "                      blockSize=9)\n",
    "# maxCorners=500: This limits the number of corners/features to be detected. The algorithm will detect at most 500 corners in the image.\n",
    "# qualityLevel=0.2: This determines the minimum accepted quality of corners. A higher value means fewer corners will be detected, but they will be more distinct. A lower value results in detecting more corners, but some may be less prominent.\n",
    "# minDistance=15: This ensures that detected corners are at least 15 pixels apart, preventing the algorithm from detecting multiple closely-packed corners.\n",
    "# blockSize=9: This parameter defines the size of the block used for corner detection. A larger block size means the algorithm will analyze a larger neighborhood around each pixel when detecting corners.\n",
    "\n",
    "# Set default image filter to PREVIEW mode\n",
    "image_filter = PREVIEW\n",
    "\n",
    "# Open a camera or video file\n",
    "source = cv2.VideoCapture(0)  # 0 for the default camera\n",
    "\n",
    "if not source.isOpened():\n",
    "    print(\"Error: Cannot open the camera.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "win_name = \"Camera Filters\"\n",
    "cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Main loop to capture frames and apply filters\n",
    "while True:\n",
    "    ret, frame = source.read()  # Capture frame from the camera\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to read frame.\")\n",
    "        break\n",
    "\n",
    "    # Apply the selected filter based on user input\n",
    "    if image_filter == PREVIEW:\n",
    "        result = frame  # No filter applied, just preview\n",
    "    elif image_filter == CANNY:\n",
    "        # Convert the frame to grayscale first\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Apply Canny edge detection\n",
    "        result = cv2.Canny(gray_frame, 80, 150)\n",
    "        # The function takes two threshold values: 80 (lower) and 150 (upper). Edges with gradients higher than the upper threshold are considered \"strong edges,\" while those between the thresholds are \"weak edges.\" This helps eliminate noise and enhance strong edges.\n",
    "    elif image_filter == BLUR:\n",
    "        # Apply a Gaussian blur\n",
    "        result = cv2.blur(frame, (13, 13))\n",
    "        # cv2.blur() applies a Gaussian blur, which smooths the image, reducing noise. The (13, 13) tuple specifies the kernel size, meaning a 13x13 pixel neighborhood is used for the blur calculation.\n",
    "    elif image_filter == FEATURES:\n",
    "        # Convert frame to grayscale\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Detect corners/features in the frame\n",
    "        corners = cv2.goodFeaturesToTrack(frame_gray, mask=None, **feature_params)\n",
    "        # The ** operator in Python is used for unpacking a dictionary into keyword arguments. \n",
    "        # When you use **feature_params inside the function call, it \"unpacks\" the dictionary so that each key-value pair is passed as a separate named argument to the cv2.goodFeaturesToTrack() function.\n",
    "        #eg.\n",
    "        #  corners = cv2.goodFeaturesToTrack(frame_gray, maxCorners=500, qualityLevel=0.2, minDistance=15, blockSize=9)\n",
    "\n",
    "        result = frame.copy()\n",
    "        # If corners are detected, mark them on the frame\n",
    "        if corners is not None:\n",
    "            for x, y in np.float32(corners).reshape(-1, 2):\n",
    "                cv2.circle(result, (int(x), int(y)), 10, (0, 255, 0), 1)\n",
    "\n",
    "    # Show the resulting frame in the window\n",
    "    cv2.imshow(win_name, result)\n",
    "\n",
    "    # Wait for user input and process the filter selection\n",
    "    key = cv2.waitKey(1)  # Capture keyboard input every 1 millisecond\n",
    "    if key == ord('q') or key == ord('Q') or key == 27:  # Exit on 'q' or 'Esc'\n",
    "        break\n",
    "    elif key == ord('c') or key == ord('C'):  # Switch to Canny Edge Detection\n",
    "        image_filter = CANNY\n",
    "    elif key == ord('b') or key == ord('B'):  # Switch to Blur filter\n",
    "        image_filter = BLUR\n",
    "    elif key == ord('f') or key == ord('F'):  # Switch to Corner feature detection\n",
    "        image_filter = FEATURES\n",
    "    elif key == ord('p') or key == ord('P'):  # Switch back to Preview mode\n",
    "        image_filter = PREVIEW\n",
    "\n",
    "# Clean up\n",
    "source.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
